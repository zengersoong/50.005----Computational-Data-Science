# 50.038 -- Computational Data Science

## Lab 1 
### Data handling
Instructor(s): Prof. Dorien Herremans  
1. Basic commands on unix
2. Scrapping with beautiful soup

## Lab 2
### Big data / Hadoop & MapReduce
Instructor(s): Prof. Dorien Herremans  
1. Hadoop filesystem commands
2. Map reduce
3. Coding map reduce for different task

## Lab 3
### Classification using Weka & Scikit-learn
Instructor(s): Prof. K.H.Lim
1. Weka, diabetes. training and testing classifiers
2. Randomtree and randomforest classifiers
3. Twitter sentiment datasets with scikit-learn
4. Count vectorizer function to count the frequency of each word
5. Training and testing classifier
6. Implement simple pipeline with Naive Baytes classifier with words
7. Removing stop-words to improve the model
8. Enhance the model by experimenting with bi-grams and tri-grams

## Lab 4
### Data visualisation in python
Instructor(s): Prof. Dorien Herremans  
Using python pandas, as well as matplotlib to visualise data
1. Python pandas dataframes
2. Matplotlib library functions and plots
3. Histograms, bar charts, line plots , box plots , scatterplots
## Lab 5
### Feature Selection and Time Series
Instructor(s): Prof. K.H.Lim   
Using Sklearn machine learning library for data pre-processing, classification, clustering . 
Using Twitter datasets for sentiment labelling. 4=positive and 0 = negative

1. Machine learning through sklearn . 
2. Data preprocessing and classification . 
3. Using different feature selections to optimise the classifer/ improve results (top - k Features, kNearestNeighbours, top-k percentile) . 
4. Using Weka with package, "Time Series Forecasting" . (Only screenshots, in weka pdf)
5. Evaluate linear regression with / without attribute(feature) selection.  

## Lab 6
### Feature Selection and Time Series
Instructor(s): Prof. K.H.Lim   
Using Weka to explore the idea of data pre-processing, as well as using Association Rule Mining.  
#### Data Sets used are :  
1. credig-g.arff dataset
2. supermarket.arff
3. iris.arff
#### Association Rule Mining/Preprocessing
1. Using unsupervised discretizer to filter the attributes
2. Using Weka's Apriori algorithm for association rule Mining
3. Identifying the features
4. Apply minimum support threshold and identifying top 10 association rules
5. Assocation rules are ranked by their associated confidence score
#### Clustering
1. Using K-means with and without normalisation
2. Observing the effects of the SSE values (Normalized vs non-normalized)

