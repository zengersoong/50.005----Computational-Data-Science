{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import reuters, imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, SimpleRNN, GRU, Dense, Dropout, Activation, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1985770747</td>\n",
       "      <td>Sun May 31 17:44:25 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>vozabala</td>\n",
       "      <td>Getting ready for another week of fun and game...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2322735567</td>\n",
       "      <td>Wed Jun 24 23:10:08 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>liannecab</td>\n",
       "      <td>http://twitpic.com/8cp6u - I want it, sooo bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1972997427</td>\n",
       "      <td>Sat May 30 10:16:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>nadhirarchangel</td>\n",
       "      <td>iloveyousincethe1stgradeitsthefirsttimewemet  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2230992481</td>\n",
       "      <td>Thu Jun 18 17:53:46 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>doughamlin</td>\n",
       "      <td>@extendr I can add :skype links but :aim links...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2053227537</td>\n",
       "      <td>Sat Jun 06 03:46:32 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Mariallama</td>\n",
       "      <td>just woke up at to rain. . . on the plus side ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label          id                          date     query             user  \\\n",
       "0      4  1985770747  Sun May 31 17:44:25 PDT 2009  NO_QUERY         vozabala   \n",
       "1      0  2322735567  Wed Jun 24 23:10:08 PDT 2009  NO_QUERY        liannecab   \n",
       "2      0  1972997427  Sat May 30 10:16:49 PDT 2009  NO_QUERY  nadhirarchangel   \n",
       "3      0  2230992481  Thu Jun 18 17:53:46 PDT 2009  NO_QUERY       doughamlin   \n",
       "4      4  2053227537  Sat Jun 06 03:46:32 PDT 2009  NO_QUERY       Mariallama   \n",
       "\n",
       "                                                text  \n",
       "0  Getting ready for another week of fun and game...  \n",
       "1    http://twitpic.com/8cp6u - I want it, sooo bad   \n",
       "2  iloveyousincethe1stgradeitsthefirsttimewemet  ...  \n",
       "3  @extendr I can add :skype links but :aim links...  \n",
       "4  just woke up at to rain. . . on the plus side ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('tweets.160k.random.csv', encoding='utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    80259\n",
       "0    79741\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess our dataset (extract relevant column, tokenize and integer encode into sequences)\n",
    "vocab_size = 20000\n",
    "tokenizer = Tokenizer(num_words= vocab_size)\n",
    "tokenizer.fit_on_texts(data['text'])\n",
    "sequences = tokenizer.texts_to_sequences(data['text'])\n",
    "tweets = sequence.pad_sequences(sequences, padding='post', maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset to training and test sets\n",
    "labels = data['label']\n",
    "labels = labels.replace(4,1) # replace label '4' with '1' to facilitate one-hot encoding\n",
    "x_train, x_test, y_train, y_test = train_test_split(tweets, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128000 train sequences\n",
      "32000 test sequences\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert our class labels to one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train) # 2 classes\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct a simple RNN model\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(vocab_size, 128))\n",
    "# model.add(SimpleRNN(128))\n",
    "# model.add(Dense(2))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "# Construct a simple LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "## Construct a simple GRU model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128))\n",
    "model.add(GRU(128))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define how our model should be trained\n",
    "model.compile(loss='categorical_crossentropy',\n",
    " optimizer='adam',\n",
    " metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102400 samples, validate on 25600 samples\n",
      "Epoch 1/3\n",
      "102400/102400 [==============================] - 74s 727us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5014\n",
      "Epoch 2/3\n",
      "102400/102400 [==============================] - 72s 702us/step - loss: 0.6932 - acc: 0.5022 - val_loss: 0.6932 - val_acc: 0.5014\n",
      "Epoch 3/3\n",
      "102400/102400 [==============================] - 71s 692us/step - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6933 - val_acc: 0.4986\n"
     ]
    }
   ],
   "source": [
    "#Train our model\n",
    "history = model.fit(x_train, y_train,\n",
    " batch_size=128,\n",
    " epochs=3,\n",
    " verbose=1,\n",
    " validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 4s 136us/step\n",
      "Test score: 0.6932984449863434\n",
      "Test accuracy: 0.496875\n"
     ]
    }
   ],
   "source": [
    "#test our model\n",
    "score = model.evaluate(x_test, y_test,\n",
    " batch_size=128, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
