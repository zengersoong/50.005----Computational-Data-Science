{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='count')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 46) # 46 classes\n",
    "y_test = keras.utils.to_categorical(y_test, 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(10000,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(46, activation='softmax')) # 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 1024)              10241024  \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 46)                47150     \n",
      "=================================================================\n",
      "Total params: 11,337,774\n",
      "Trainable params: 11,337,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    " optimizer='adam',\n",
    " metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.6968 - acc: 0.8433 - val_loss: 0.9475 - val_acc: 0.8131\n",
      "Epoch 2/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.4490 - acc: 0.8981 - val_loss: 0.9791 - val_acc: 0.8131\n",
      "Epoch 3/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.3261 - acc: 0.9254 - val_loss: 1.0249 - val_acc: 0.8076\n",
      "Epoch 4/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.2700 - acc: 0.9399 - val_loss: 1.0683 - val_acc: 0.8120\n",
      "Epoch 5/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.2548 - acc: 0.9438 - val_loss: 1.0888 - val_acc: 0.8109\n",
      "Epoch 6/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.2395 - acc: 0.9498 - val_loss: 1.0628 - val_acc: 0.8209\n",
      "Epoch 7/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.2206 - acc: 0.9548 - val_loss: 1.1033 - val_acc: 0.8187\n",
      "Epoch 8/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.2020 - acc: 0.9553 - val_loss: 1.0716 - val_acc: 0.8120\n",
      "Epoch 9/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.1987 - acc: 0.9543 - val_loss: 1.1035 - val_acc: 0.8187\n",
      "Epoch 10/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.1924 - acc: 0.9552 - val_loss: 1.0751 - val_acc: 0.8154\n",
      "Epoch 11/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.1850 - acc: 0.9584 - val_loss: 1.0834 - val_acc: 0.8187\n",
      "Epoch 12/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.1746 - acc: 0.9607 - val_loss: 1.1495 - val_acc: 0.8087\n",
      "Epoch 13/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.1679 - acc: 0.9587 - val_loss: 1.1263 - val_acc: 0.8198\n",
      "Epoch 14/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.1798 - acc: 0.9577 - val_loss: 1.1498 - val_acc: 0.8020\n",
      "Epoch 15/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.1708 - acc: 0.9579 - val_loss: 1.1007 - val_acc: 0.8131\n",
      "Epoch 16/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.1598 - acc: 0.9589 - val_loss: 1.1506 - val_acc: 0.8042\n",
      "Epoch 17/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.1581 - acc: 0.9605 - val_loss: 1.1558 - val_acc: 0.8042\n",
      "Epoch 18/20\n",
      "8083/8083 [==============================] - 11s 1ms/step - loss: 0.1601 - acc: 0.9584 - val_loss: 1.1446 - val_acc: 0.8142\n",
      "Epoch 19/20\n",
      "8083/8083 [==============================] - 12s 2ms/step - loss: 0.1497 - acc: 0.9599 - val_loss: 1.1572 - val_acc: 0.8154\n",
      "Epoch 20/20\n",
      "8083/8083 [==============================] - 16s 2ms/step - loss: 0.1641 - acc: 0.9586 - val_loss: 1.2236 - val_acc: 0.8087\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    " batch_size=128,\n",
    " epochs=20,#changed from 10*\n",
    " verbose=1,\n",
    " validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1853435315516838\n",
      "Accuracy: 0.8072128228491582\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Loss:', score[0])\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
